{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f41ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb import Client\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21d41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load the Cleaned Dataset\n",
    "df_filtered = pd.read_csv('../data/filtered_complaints.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b12787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40aef681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create the Cleaned Narrative Column\n",
    "df_filtered['cleaned_narrative'] = df_filtered['Consumer complaint narrative'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Text Chunking\n",
    "chunk_size = 512  # Number of characters per chunk\n",
    "chunk_overlap = 20  # Overlap between chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "# Function to chunk narratives\n",
    "def chunk_narratives(narrative):\n",
    "    return text_splitter.split_text(narrative)\n",
    "\n",
    "# Apply chunking to the cleaned narratives\n",
    "df_filtered['chunks'] = df_filtered['cleaned_narrative'].apply(chunk_narratives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7940ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Flatten DataFrame for Embedding\n",
    "chunks = []\n",
    "for idx, row in df_filtered.iterrows():\n",
    "    for chunk in row['chunks']:\n",
    "        chunks.append({\n",
    "            'id': row['Complaint ID'],\n",
    "            'product': row['Product'],\n",
    "            'chunk': chunk\n",
    "        })\n",
    "\n",
    "df_chunks = pd.DataFrame(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5582bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Choose an Embedding Model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Generate Embeddings in Batches\n",
    "batch_size = 16  # Adjust based on your memory capacity\n",
    "embeddings = []\n",
    "\n",
    "for i in range(0, len(df_chunks), batch_size):\n",
    "    batch = df_chunks['chunk'][i:i + batch_size].tolist()\n",
    "    embeddings.extend(model.encode(batch).tolist())\n",
    "\n",
    "df_chunks['embedding'] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72ad7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Create or Access a Vector Store Using ChromaDB\n",
    "client = Client()\n",
    "\n",
    "# Access existing collection or create a new one\n",
    "# try:\n",
    "#     vector_store = client.get_collection(\"complaint_embeddings\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error accessing collection: {e}\")\n",
    "vector_store = client.create_collection(\"complaints_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d783d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for _, row in df_chunks.iterrows():\n",
    "    try:\n",
    "        # Validate data\n",
    "        if not isinstance(row['embedding'], list) or not all(isinstance(x, float) for x in row['embedding']):\n",
    "            print(f\"Skipping invalid embedding for ID {row['id']}: {row['embedding']}\")\n",
    "            continue\n",
    "        if row['chunk'] is None or not isinstance(row['chunk'], str):\n",
    "            print(f\"Skipping invalid chunk for ID {row['id']}: {row['chunk']}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert embedding to numpy array if required by vector store\n",
    "        embedding = np.array(row['embedding'], dtype=np.float32)\n",
    "        \n",
    "        # Add to vector store\n",
    "        vector_store.add(\n",
    "            ids=[str(row['id'])],\n",
    "            embeddings=[embedding],\n",
    "            documents=[row['chunk']],\n",
    "            metadatas=[{'id': str(row['id']), 'product': row['product']}]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ID {row['id']}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Persist the Vector Store\n",
    "vector_store.persist(\"vector_store/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b5a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
